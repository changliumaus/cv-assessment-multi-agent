{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Assessment Agents Testing Notebook\n",
    "\n",
    "This notebook allows you to test each agent individually with custom inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Enable autoreload to reflect source code changes without kernel restart\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete!\n"
     ]
    }
   ],
   "source": [
    "# Import all agents\n",
    "from cv_assessment.agents.cv_parser_agent import CVParserAgent\n",
    "from cv_assessment.agents.job_analyzer_agent import JobAnalyzerAgent\n",
    "from cv_assessment.agents.skills_matcher_agent import SkillsMatcherAgent\n",
    "from cv_assessment.agents.experience_evaluator_agent import ExperienceEvaluatorAgent\n",
    "from cv_assessment.agents.culture_fit_agent import CultureFitAgent\n",
    "from cv_assessment.agents.final_scorer_agent import FinalScorerAgent\n",
    "\n",
    "# Import models\n",
    "from cv_assessment.models.schemas import CVData, JobDescription\n",
    "\n",
    "print(\"Imports complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV length: 5729 characters\n",
      "Job description length: 3480 characters\n",
      "\n",
      "Sample CV (first 500 chars):\n",
      "Dr. Sarah Chen\n",
      "Senior Data Scientist\n",
      "\n",
      "Email: sarah.chen@email.com\n",
      "Phone: +1 (555) 987-6543\n",
      "Location: New York, NY\n",
      "LinkedIn: linkedin.com/in/sarahchen\n",
      "GitHub: github.com/sarahchen\n",
      "\n",
      "PROFESSIONAL SUMMARY\n",
      "Accomplished Senior Data Scientist with 6+ years of experience in machine learning, deep learning,\n",
      "and statistical analysis. Expert in Python, R, and SQL with a proven track record of deploying\n",
      "production-grade ML models that drive business impact. Ph.D. in Computer Science with specialization\n",
      "in N\n"
     ]
    }
   ],
   "source": [
    "# Load sample CV and job description\n",
    "cv_path = project_root / \"examples\" / \"sample_cv_data_scientist.txt\"\n",
    "job_path = project_root / \"examples\" /\"Senior Backend Engineer.txt\"\n",
    "# \"research_scientist_job.txt\"\n",
    "# \"AI_enginner.txt\" \n",
    "# \"sample_cv.txt\"\n",
    "\n",
    "with open(cv_path, 'r') as f:\n",
    "    sample_cv_text = f.read()\n",
    "\n",
    "with open(job_path, 'r') as f:\n",
    "    sample_job_text = f.read()\n",
    "\n",
    "print(f\"CV length: {len(sample_cv_text)} characters\")\n",
    "print(f\"Job description length: {len(sample_job_text)} characters\")\n",
    "print(\"\\nSample CV (first 500 chars):\")\n",
    "print(sample_cv_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: CV Parser Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 10:41:43 - cv_assessment.utils.llm_factory - INFO - Creating LLM instance: provider=gemini, model=gemini-2.0-flash, temperature=0.4\n",
      "2025-11-09 10:41:43 - cv_assessment.agents.base_agent - INFO - Initialized agent: CV Parser\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Parser Agent initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize CV Parser Agent\n",
    "cv_parser = CVParserAgent()\n",
    "print(\"CV Parser Agent initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 10:41:46 - cv_assessment.agents.cv_parser_agent - INFO - Parsing CV text\n",
      "2025-11-09 10:41:55 - cv_assessment.agents.cv_parser_agent - INFO - Successfully parsed CV for candidate: Dr. Sarah Chen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate: Dr. Sarah Chen\n",
      "Email: sarah.chen@email.com\n",
      "Skills: 59 found\n",
      "Work Experience: 3 positions\n",
      "Education: 3 entries\n",
      "\n",
      "Skills:\n",
      "  - Python, 6.0 years), expert, Programming Language\n",
      "  - R, 5.0 years), advanced, Programming Language\n",
      "  - SQL, 6.0 years), advanced, Programming Language\n",
      "  - Java, 2.0 years), intermediate, Programming Language\n",
      "  - Scala, 2.0 years), intermediate, Programming Language\n",
      "  - Scikit-learn, None years), None, Machine Learning & AI\n",
      "  - TensorFlow, None years), None, Machine Learning & AI\n",
      "  - PyTorch, None years), None, Machine Learning & AI\n",
      "  - Keras, None years), None, Machine Learning & AI\n",
      "  - XGBoost, None years), None, Machine Learning & AI\n",
      "  - LightGBM, None years), None, Machine Learning & AI\n",
      "  - CatBoost, None years), None, Machine Learning & AI\n",
      "  - Hugging Face Transformers, None years), None, Machine Learning & AI\n",
      "  - spaCy, None years), None, Machine Learning & AI\n",
      "  - NLTK, None years), None, Machine Learning & AI\n",
      "  - OpenCV, None years), None, Machine Learning & AI\n",
      "  - PIL, None years), None, Machine Learning & AI\n",
      "  - Apache Spark, None years), None, Data Engineering\n",
      "  - PySpark, None years), None, Data Engineering\n",
      "  - Apache Kafka, None years), None, Data Engineering\n",
      "  - Airflow, None years), None, Data Engineering\n",
      "  - Prefect, None years), None, Data Engineering\n",
      "  - Hadoop, None years), None, Data Engineering\n",
      "  - Hive, None years), None, Data Engineering\n",
      "  - Delta Lake, None years), None, Data Engineering\n",
      "  - AWS SageMaker, None years), None, Cloud Platform\n",
      "  - AWS EC2, None years), None, Cloud Platform\n",
      "  - AWS S3, None years), None, Cloud Platform\n",
      "  - AWS Lambda, None years), None, Cloud Platform\n",
      "  - AWS EMR, None years), None, Cloud Platform\n",
      "  - Google Cloud Platform Vertex AI, None years), None, Cloud Platform\n",
      "  - Google Cloud Platform BigQuery, None years), None, Cloud Platform\n",
      "  - Docker, None years), None, Cloud & Infrastructure\n",
      "  - Kubernetes, None years), None, Cloud & Infrastructure\n",
      "  - MLflow, None years), None, MLOps\n",
      "  - Weights & Biases, None years), None, MLOps\n",
      "  - DVC, None years), None, MLOps\n",
      "  - Tableau, None years), None, Data Visualization\n",
      "  - Power BI, None years), None, Data Visualization\n",
      "  - Plotly, None years), None, Data Visualization\n",
      "  - Matplotlib, None years), None, Data Visualization\n",
      "  - Seaborn, None years), None, Data Visualization\n",
      "  - D3.js, None years), None, Data Visualization\n",
      "  - Jupyter, None years), None, Data Visualization\n",
      "  - Google Colab, None years), None, Data Visualization\n",
      "  - PostgreSQL, None years), None, Database\n",
      "  - MySQL, None years), None, Database\n",
      "  - MongoDB, None years), None, Database\n",
      "  - Cassandra, None years), None, Database\n",
      "  - Redis, None years), None, Database\n",
      "  - Elasticsearch, None years), None, Database\n",
      "  - Snowflake, None years), None, Database\n",
      "  - Redshift, None years), None, Database\n",
      "  - A/B Testing, None years), None, Statistical Analysis\n",
      "  - Experimentation, None years), None, Statistical Analysis\n",
      "  - Bayesian Statistics, None years), None, Statistical Analysis\n",
      "  - Time Series Analysis, None years), None, Statistical Analysis\n",
      "  - Causal Inference, None years), None, Statistical Analysis\n",
      "  - Hypothesis Testing, None years), None, Statistical Analysis\n",
      "  - ['Led development of a recommendation engine using collaborative filtering and deep learning,\\n  increasing user engagement by 35% and revenue by $12M annually', 'Built and deployed a real-time fraud detection system processing 1M+ transactions daily with\\n  99.2% accuracy, reducing fraud losses by 45%', 'Architected end-to-end MLOps pipeline using Airflow, MLflow, and Kubernetes, reducing model\\n  deployment time from weeks to days', 'Developed NLP-based customer sentiment analysis system analyzing 500K+ customer reviews monthly,\\n  providing actionable insights to product and marketing teams', 'Mentored team of 3 junior data scientists and conducted regular ML workshops'],(None)\n",
      "  - ['Developed predictive models for customer churn prediction achieving 87% accuracy, enabling\\n  proactive retention strategies that reduced churn by 22%', 'Created automated reporting dashboards in Tableau reducing manual reporting time by 80%', 'Built time series forecasting models for demand prediction with MAPE < 5%, optimizing\\n  inventory management and reducing costs by $3M annually', 'Implemented A/B testing framework for product experimentation, enabling data-driven\\n  decision making across 50+ experiments', 'Collaborated with engineering team to productionize 8 ML models in AWS environment'],(None)\n",
      "  - ['Conducted cutting-edge research in Natural Language Processing and published 4 papers in\\n  top-tier conferences (ACL, EMNLP)', 'Developed novel deep learning architectures for text classification and named entity recognition', 'Built large-scale datasets and trained transformer models for domain-specific applications', 'Collaborated with industry partners to apply research to real-world problems'],(None)\n",
      "  - Ph.D. in Computer Science (Natural Language Processing) from Massachusetts Institute of Technology (2019, 3.95)\n",
      "  - M.S. in Statistics from Stanford University (2016, 3.9)\n",
      "  - B.S. in Mathematics & Computer Science from University of California, Berkeley (2014, 3.95)\n",
      "Accomplished Senior Data Scientist with 6+ years of experience in machine learning, deep learning,\n",
      "and statistical analysis. Expert in Python, R, and SQL with a proven track record of deploying\n",
      "production-grade ML models that drive business impact. Ph.D. in Computer Science with specialization\n",
      "in Natural Language Processing. Passionate about turning data into actionable insights and building\n",
      "scalable ML pipelines.\n",
      "\n",
      "['English', 'Mandarin Chinese', 'Spanish']\n",
      "['AWS Certified Machine Learning - Specialty (2022)', 'Google Cloud Professional Data Engineer (2021)', 'TensorFlow Developer Certificate (2020)']\n"
     ]
    }
   ],
   "source": [
    "# Parse the CV\n",
    "cv_data = cv_parser.parse_cv(sample_cv_text)\n",
    "\n",
    "print(f\"Candidate: {cv_data.candidate_name}\")\n",
    "print(f\"Email: {cv_data.email}\")\n",
    "print(f\"Skills: {len(cv_data.skills)} found\")\n",
    "print(f\"Work Experience: {len(cv_data.work_experience)} positions\")\n",
    "print(f\"Education: {len(cv_data.education)} entries\")\n",
    "print(\"\\nSkills:\")\n",
    "for skill in cv_data.skills:\n",
    "    print(f\"  - {skill.name}, {skill.years_experience} years), {skill.skill_level}, {skill.category}\")\n",
    "for work in cv_data.work_experience:\n",
    "    print(f\"  - {work.responsibilities},({work.duration_months})\")\n",
    "for edu in cv_data.education:\n",
    "    print(f\"  - {edu.degree} in {edu.field_of_study} from {edu.institution} ({edu.graduation_year}, {edu.gpa})\")\n",
    "print(f\"{cv_data.summary}\\n\")\n",
    "print(f\"{cv_data.languages}\")\n",
    "print(f\"{cv_data.certifications}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Job Analyzer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 10:42:08 - cv_assessment.utils.llm_factory - INFO - Creating LLM instance: provider=gemini, model=gemini-2.0-flash, temperature=0.4\n",
      "2025-11-09 10:42:08 - cv_assessment.agents.base_agent - INFO - Initialized agent: Job Analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Analyzer Agent initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize Job Analyzer Agent\n",
    "job_analyzer = JobAnalyzerAgent()\n",
    "print(\"Job Analyzer Agent initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 10:42:09 - cv_assessment.agents.job_analyzer_agent - INFO - Analyzing job description\n",
      "2025-11-09 10:42:12 - cv_assessment.agents.job_analyzer_agent - INFO - Successfully analyzed job: Senior Backend Engineer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Title: Senior Backend Engineer\n",
      "Company: InnovateTech Solutions\n",
      "Location: San Francisco, CA (Hybrid)\n",
      "\n",
      "Necessary Experience (1):\n",
      "  - 5+ years of professional software engineering experience\n",
      "\n",
      "Necessary Skills (17):\n",
      "  - name='Python' skill_level=None years_experience=None category=None\n",
      "  - name='Go' skill_level=None years_experience=None category=None\n",
      "  - name='Django' skill_level=None years_experience=None category=None\n",
      "  - name='Flask' skill_level=None years_experience=None category=None\n",
      "  - name='FastAPI' skill_level=None years_experience=None category=None\n",
      "  - name='RESTful API' skill_level=None years_experience=None category=None\n",
      "  - name='microservices architecture' skill_level=None years_experience=None category=None\n",
      "  - name='SQL databases' skill_level=None years_experience=None category=None\n",
      "  - name='PostgreSQL' skill_level=None years_experience=None category=None\n",
      "  - name='MySQL' skill_level=None years_experience=None category=None\n",
      "  - name='query optimization' skill_level=None years_experience=None category=None\n",
      "  - name='AWS' skill_level=None years_experience=None category=None\n",
      "  - name='GCP' skill_level=None years_experience=None category=None\n",
      "  - name='Azure' skill_level=None years_experience=None category=None\n",
      "  - name='distributed systems' skill_level=None years_experience=None category=None\n",
      "  - name='Docker' skill_level=None years_experience=None category=None\n",
      "  - name='Kubernetes' skill_level=None years_experience=None category=None\n",
      "\n",
      "Nice-to-Have Experience (1):\n",
      "  - Experience in fintech or payment processing systems\n",
      "\n",
      "Nice-to-Have Skills (12):\n",
      "  - name='Kafka' skill_level=None years_experience=None category=None\n",
      "  - name='RabbitMQ' skill_level=None years_experience=None category=None\n",
      "  - name='NoSQL databases' skill_level=None years_experience=None category=None\n",
      "  - name='MongoDB' skill_level=None years_experience=None category=None\n",
      "  - name='Redis' skill_level=None years_experience=None category=None\n",
      "  - name='Prometheus' skill_level=None years_experience=None category=None\n",
      "  - name='Grafana' skill_level=None years_experience=None category=None\n",
      "  - name='DataDog' skill_level=None years_experience=None category=None\n",
      "  - name='Terraform' skill_level=None years_experience=None category=None\n",
      "  - name='CloudFormation' skill_level=None years_experience=None category=None\n",
      "  - name='GraphQL' skill_level=None years_experience=None category=None\n",
      "  - name='PCI-DSS' skill_level=None years_experience=None category=None\n",
      "\n",
      "Responsibilities (8):\n",
      "  - Design, develop, and maintain scalable backend services and APIs\n",
      "  - Build and optimize high-throughput payment processing systems\n",
      "  - Collaborate with cross-functional teams including Product, Frontend, and DevOps\n",
      "  - Lead technical design discussions and architecture reviews\n",
      "  - Mentor junior and mid-level engineers\n",
      "  - Participate in on-call rotation for production support\n",
      "  - Write clean, maintainable, and well-tested code\n",
      "  - Contribute to technical documentation and best practices\n",
      "\n",
      "Education (1):\n",
      "  - Bachelor's degree in Computer Science or equivalent experience\n",
      "\n",
      "Leadership Requirements (2):\n",
      "  - Lead technical design discussions and architecture reviews\n",
      "  - Mentor junior and mid-level engineers\n",
      "\n",
      "Soft Skills Requirements (2):\n",
      "  - Excellent problem-solving and debugging skills\n",
      "  - Strong communication and collaboration abilities\n"
     ]
    }
   ],
   "source": [
    "# Analyze the job description\n",
    "job_description = job_analyzer.analyze_job(sample_job_text)\n",
    "\n",
    "print(f\"Job Title: {job_description.job_title}\")\n",
    "print(f\"Company: {job_description.company}\")\n",
    "print(f\"Location: {job_description.location}\")\n",
    "print(f\"\\nNecessary Experience ({len(job_description.necessary_experince)}):\")\n",
    "for exp in job_description.necessary_experince:\n",
    "    print(f\"  - {exp}\")\n",
    "print(f\"\\nNecessary Skills ({len(job_description.necessary_skills)}):\")\n",
    "for skill in job_description.necessary_skills:\n",
    "    print(f\"  - {skill}\")\n",
    "print(f\"\\nNice-to-Have Experience ({len(job_description.nice_to_have_experience)}):\")\n",
    "for exp in job_description.nice_to_have_experience:\n",
    "    print(f\"  - {exp}\")\n",
    "print(f\"\\nNice-to-Have Skills ({len(job_description.nice_to_have_skills)}):\")\n",
    "for skill in job_description.nice_to_have_skills:\n",
    "    print(f\"  - {skill}\")\n",
    "print(f\"\\nResponsibilities ({len(job_description.responsibilities)}):\")\n",
    "for resp in job_description.responsibilities:\n",
    "    print(f\"  - {resp}\")\n",
    "print(f\"\\nEducation ({len(job_description.education)}):\")\n",
    "for edu in job_description.education:\n",
    "    print(f\"  - {edu}\")\n",
    "print(f\"\\nLeadership Requirements ({len(job_description.leadership)}):\")\n",
    "for lead in job_description.leadership:\n",
    "    print(f\"  - {lead}\")\n",
    "print(f\"\\nSoft Skills Requirements ({len(job_description.soft_skills_requirement)}):\")\n",
    "for skill in job_description.soft_skills_requirement:\n",
    "    print(f\"  - {skill}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Skills Matcher Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 10:42:19 - cv_assessment.utils.llm_factory - INFO - Creating LLM instance: provider=gemini, model=gemini-2.0-flash, temperature=0.4\n",
      "2025-11-09 10:42:19 - cv_assessment.agents.base_agent - INFO - Initialized agent: Skills Matcher\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills Matcher Agent initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize Skills Matcher Agent\n",
    "skills_matcher = SkillsMatcherAgent()\n",
    "print(\"Skills Matcher Agent initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 10:42:21 - cv_assessment.agents.skills_matcher_agent - INFO - Matching candidate skills to job requirements\n",
      "2025-11-09 10:42:21 - cv_assessment.agents.skills_matcher_agent - INFO - Skill match prompt tokens: 1078\n",
      "2025-11-09 10:42:24 - cv_assessment.agents.skills_matcher_agent - INFO - Skill match score: 0.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Score: 0.65\n",
      "\n",
      "Matched Skills (8):\n",
      "  ✓ Python\n",
      "  ✓ SQL databases\n",
      "  ✓ PostgreSQL\n",
      "  ✓ MySQL\n",
      "  ✓ AWS\n",
      "  ✓ GCP\n",
      "  ✓ Docker\n",
      "  ✓ Kubernetes\n",
      "\n",
      "Missing Skills (8):\n",
      "  ✗ Go\n",
      "  ✗ Django\n",
      "  ✗ Flask\n",
      "  ✗ FastAPI\n",
      "  ✗ RESTful API\n",
      "\n",
      "Partial Matches (1):\n",
      "  ~ distributed systems\n",
      "\n",
      "Gap Analysis:\n",
      "The candidate possesses a Ph.D. in Computer Science and has extensive experience in data science, machine learning, and related technologies. The candidate meets the education requirements and has a strong foundation in Python, SQL, AWS, GCP, Docker, and Kubernetes. The candidate is missing experience with Go, Django, Flask, FastAPI, RESTful API, microservices architecture, Azure, and query optimization. The candidate also possesses several preferred skills such as Kafka, MongoDB, Redis. Overall, the candidate demonstrates a strong skill set that aligns well with the job requirements, but there are some gaps in specific technologies and architectural patterns.\n"
     ]
    }
   ],
   "source": [
    "# Match skills\n",
    "skill_match = skills_matcher.match_skills(cv_data, job_description)\n",
    "\n",
    "print(f\"Match Score: {skill_match.match_score:.2f}\")\n",
    "print(f\"\\nMatched Skills ({len(skill_match.matched_skills)}):\")\n",
    "for skill in skill_match.matched_skills[:10]:\n",
    "    print(f\"  ✓ {skill}\")\n",
    "print(f\"\\nMissing Skills ({len(skill_match.missing_skills)}):\")\n",
    "for skill in skill_match.missing_skills[:5]:\n",
    "    print(f\"  ✗ {skill}\")\n",
    "print(f\"\\nPartial Matches ({len(skill_match.partial_matches)}):\")\n",
    "for skill in skill_match.partial_matches[:5]:\n",
    "    print(f\"  ~ {skill}\")\n",
    "print(f\"\\nGap Analysis:\\n{skill_match.skill_gap_analysis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Experience Evaluator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 10:42:37 - cv_assessment.utils.llm_factory - INFO - Creating LLM instance: provider=gemini, model=gemini-2.0-flash, temperature=0.4\n",
      "2025-11-09 10:42:37 - cv_assessment.agents.base_agent - INFO - Initialized agent: Experience Evaluator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience Evaluator Agent initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize Experience Evaluator Agent\n",
    "experience_evaluator = ExperienceEvaluatorAgent()\n",
    "print(\"Experience Evaluator Agent initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 10:42:38 - cv_assessment.agents.experience_evaluator_agent - INFO - Evaluating candidate experience\n",
      "2025-11-09 10:42:41 - cv_assessment.agents.experience_evaluator_agent - INFO - Experience Evaluation  prompt tokens: 657\n",
      "2025-11-09 10:42:41 - cv_assessment.agents.experience_evaluator_agent - INFO - Experience evaluation: Mid, score: 0.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience Score: 0.30\n",
      "Total Years: 6.5\n",
      "Relevant Years: 0.0\n",
      "Experience Level: Mid\n",
      "\n",
      "Relevant Roles:\n",
      "\n",
      "Key Achievements:\n",
      "\n",
      "Analysis:\n",
      "The candidate has 6.5 years of experience in data science roles. However, the candidate lacks the required 5+ years of professional software engineering experience. The candidate's experience is primarily in data science, machine learning, and research, which does not directly align with the responsibilities of a Senior Backend Engineer, such as designing and maintaining scalable backend services and APIs. The candidate also lacks experience in fintech or payment processing systems. Therefore, the experience match is low.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate experience\n",
    "experience_eval = experience_evaluator.evaluate_experience(cv_data, job_description)\n",
    "\n",
    "print(f\"Experience Score: {experience_eval.experience_score:.2f}\")\n",
    "print(f\"Total Years: {experience_eval.total_years_experience}\")\n",
    "print(f\"Relevant Years: {experience_eval.relevant_years_experience}\")\n",
    "print(f\"Experience Level: {experience_eval.experience_level}\")\n",
    "print(f\"\\nRelevant Roles:\")\n",
    "for role in experience_eval.relevant_roles:\n",
    "    print(f\"  - {role}\")\n",
    "print(f\"\\nKey Achievements:\")\n",
    "for achievement in experience_eval.key_achievements[:5]:\n",
    "    print(f\"  - {achievement}\")\n",
    "print(f\"\\nAnalysis:\\n{experience_eval.analysis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: Culture Fit Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 10:42:45 - cv_assessment.utils.llm_factory - INFO - Creating LLM instance: provider=gemini, model=gemini-2.0-flash, temperature=0.4\n",
      "2025-11-09 10:42:45 - cv_assessment.agents.base_agent - INFO - Initialized agent: Culture Fit Assessor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Culture Fit Agent initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize Culture Fit Agent\n",
    "culture_fit = CultureFitAgent()\n",
    "print(\"Culture Fit Agent initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 10:42:59 - cv_assessment.agents.culture_fit_agent - INFO - Assessing culture fit and soft skills\n",
      "2025-11-09 10:43:00 - cv_assessment.agents.culture_fit_agent - INFO - Culture fit score: 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Culture Fit Score: 0.75\n",
      "\n",
      "Soft Skills Identified:\n",
      "  - Communication\n",
      "  - Collaboration\n",
      "  - Problem-solving\n",
      "  - Initiative and ownership\n",
      "  - Mentoring\n",
      "\n",
      "Leadership Indicators:\n",
      "  - Led development teams\n",
      "  - Reduced model deployment time\n",
      "  - Proactive retention strategies\n",
      "  - Built automated reporting dashboards\n",
      "\n",
      "Notes:\n",
      "Dr. Chen demonstrates strong leadership and collaboration skills, aligning well with the job requirements. Her experience in leading development teams and mentoring junior engineers is a good fit for the leadership aspects of the role. Her CV showcases excellent communication through clear articulation of responsibilities and achievements. The main area for improvement is the lack of direct backend engineering experience, which slightly lowers the overall culture fit score.\n"
     ]
    }
   ],
   "source": [
    "# Assess culture fit\n",
    "culture_assessment = culture_fit.assess_culture_fit(cv_data, job_description)\n",
    "\n",
    "print(f\"Culture Fit Score: {culture_assessment.culture_fit_score:.2f}\")\n",
    "print(f\"\\nSoft Skills Identified:\")\n",
    "for skill in culture_assessment.soft_skills_identified:\n",
    "    print(f\"  - {skill}\")\n",
    "print(f\"\\nLeadership Indicators:\")\n",
    "for indicator in culture_assessment.leadership_indicators:\n",
    "    print(f\"  - {indicator}\")\n",
    "print(f\"\\nNotes:\\n{culture_assessment.notes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 6: Final Scorer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 10:43:03 - cv_assessment.utils.llm_factory - INFO - Creating LLM instance: provider=gemini, model=gemini-2.0-flash, temperature=0.4\n",
      "2025-11-09 10:43:03 - cv_assessment.agents.base_agent - INFO - Initialized agent: Final Scorer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Scorer Agent initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize Final Scorer Agent\n",
    "final_scorer = FinalScorerAgent()\n",
    "print(\"Final Scorer Agent initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 10:43:05 - cv_assessment.agents.final_scorer_agent - INFO - Creating final assessment\n",
      "2025-11-09 10:43:05 - cv_assessment.agents.final_scorer_agent - INFO - Final scorer prompt tokens: 285\n",
      "2025-11-09 10:43:08 - cv_assessment.agents.final_scorer_agent - INFO - Final assessment complete: weak_match (score: 0.53)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL ASSESSMENT\n",
      "================================================================================\n",
      "\n",
      "Overall Score: 0.53\n",
      "Recommendation: weak_match\n",
      "\n",
      "Strengths:\n",
      "  + Strong background in Python and SQL databases\n",
      "  + Experience with AWS, GCP, Docker, and Kubernetes\n",
      "  + Demonstrated leadership and collaboration skills\n",
      "  + Ph.D. in Computer Science\n",
      "\n",
      "Concerns:\n",
      "  - Limited professional software engineering experience\n",
      "  - Lacks experience with Go, Django, Flask, FastAPI, RESTful API, and microservices architecture\n",
      "  - Missing experience with Azure and query optimization\n",
      "\n",
      "Summary:\n",
      "Dr. Chen possesses a strong academic background and relevant skills in Python, SQL databases, and cloud technologies. Her leadership and collaboration skills align well with the job requirements. However, her limited professional software engineering experience and lack of experience with key technologies like Go, Django, Flask, FastAPI, RESTful API, microservices architecture, and Azure raise concerns. While her skills in data science and machine learning are valuable, the gaps in backend engineering experience make her a weak match for the Senior Backend Engineer position.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create final assessment\n",
    "final_assessment = final_scorer.create_final_assessment(\n",
    "    cv_data=cv_data,\n",
    "    job_description=job_description,\n",
    "    skill_match=skill_match,\n",
    "    experience_eval=experience_eval,\n",
    "    culture_fit=culture_assessment\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"FINAL ASSESSMENT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nOverall Score: {final_assessment.overall_score:.2f}\")\n",
    "print(f\"Recommendation: {final_assessment.recommendation}\")\n",
    "print(f\"\\nStrengths:\")\n",
    "for strength in final_assessment.strengths:\n",
    "    print(f\"  + {strength}\")\n",
    "print(f\"\\nConcerns:\")\n",
    "for concern in final_assessment.concerns:\n",
    "    print(f\"  - {concern}\")\n",
    "print(f\"\\nSummary:\\n{final_assessment.summary}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-assessment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
